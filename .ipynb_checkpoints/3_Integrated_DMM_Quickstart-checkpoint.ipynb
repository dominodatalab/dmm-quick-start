{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c01e6a6-9c77-473d-a1f5-d7e2f427df76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample Integrated Model with Domino Model Monitoring\n",
    "\n",
    "This is an example notebook to set up integrated Domino Model Monitoring of models hosted as Domino Model APIs.\n",
    "\n",
    "## Background\n",
    "\n",
    "Integrated model monitoring is intended to be used when the model itself deployed as a model API within your Domino cluster. This notebook walks through:\n",
    "\n",
    "(1) Registering the training data snapshot used for training the model as a TrainingDataset.\n",
    "\n",
    "(2) Adding in the Prediction Capture Client to your model, and deploying the model as a Domino Model API. This allows Domino to automatically capture the scoring data & model predictions for you.\n",
    "\n",
    "(3) Setting up integrated Domino Model Monitoring for your Model API. \n",
    "\n",
    "(4) (Optional) Attaching a Domino Model Monitoring datasource for ingesting ground truth labels. To automate this step, the notebook walks through setting up a scheduled job to send ground truth labels to the datasource so that Domnino can monitor the model's accuracy over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1b6d-ecce-4c7b-8281-9a71a3495707",
   "metadata": {},
   "source": [
    "### Step 1: Create and Register the Training Dataset\n",
    "\n",
    "In the integrated model scenario, we'll assume the model is trained in Domino's Workbench, meaning the model's training data was brought into a Domino run. With integrated model monitoring, rather than uploading the training data set to an external data source, we can register and version it as a **TrainingSet**in Domino, and automatically ingest it when the integrated model is registered.\n",
    "\n",
    "A **TrainingSet** is a versioned set of data, column information, and other metadata. See documentation here:\n",
    "\n",
    "https://docs.dominodatalab.com/en/latest/api_guide/440de9/trainingsets-use-cases/\n",
    "\n",
    "To register a training dataset, we'll import the Domino training sets client, set the training set metadata, and store a version in Domino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffd2be1-4a18-420e-945d-d319442a5547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSetVersion iris_python_multi_classification_monitor_workshop:3\n"
     ]
    }
   ],
   "source": [
    "from domino_data.training_sets import client, model\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_name = os.environ['DOMINO_USER_NAME']\n",
    "\n",
    "# Load the original Iris training dataset, and split into train and test sets\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"data\"], data[\"target\"], test_size=0.2\n",
    ")\n",
    "\n",
    "# Create the training dataframe\n",
    "target_column_name = \"variety\"\n",
    "\n",
    "training_df = pd.DataFrame(data = X_train, columns = data.feature_names)\n",
    "training_df[target_column_name] = [data.target_names[y] for y in y_train]\n",
    "\n",
    "# Create the training set version to store this snapshot.\n",
    "tsv = client.create_training_set_version(\n",
    "    training_set_name=\"iris_python_multi_classification_{}\".format(os.environ.get('DOMINO_PROJECT_NAME')),\n",
    "    df=training_df,\n",
    "    key_columns=[],\n",
    "    target_columns=[target_column_name],\n",
    "    exclude_columns=[],\n",
    "    meta={\"experiment_id\": \"0.1\"},\n",
    "    monitoring_meta=model.MonitoringMeta(**{\n",
    "        \"categorical_columns\": [target_column_name],\n",
    "        \"timestamp_columns\": [],\n",
    "        \"ordinal_columns\": []\n",
    "    })\n",
    ")\n",
    "\n",
    "print(f\"TrainingSetVersion {tsv.training_set_name}:{tsv.number}\")\n",
    "\n",
    "# Save the training data locally for reference\n",
    "training_df.to_csv(\"data/iris_train_data.csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2db7f-89b7-4646-92d7-6aae3bf69315",
   "metadata": {},
   "source": [
    "### Step 2: Train the Model\n",
    "\n",
    "Since this example uses a Domino-hosted model API, we'll start by training a simple model to deploy in Domino.\n",
    "\n",
    "For integrated model monitoring, we train the model the same way we would any other machine learning model. However, when we create the model class that the model API will ultimately call, we need to include the Domino **DataCaptureClient**, which automatically captures the scoring data and model predictions.\n",
    "\n",
    "To configure the **DataCaptureClient** for this model, we need to pass it the names of the features we want to monitor, as well as the name of the model prediction (or target) column, to capture the model's predictions.\n",
    "\n",
    "The DataCaptureClient is documented here:\n",
    "\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/93e5c0/set-up-prediction-capture/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0815351c-c786-4e22-8d2c-8284d288c6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI: http://127.0.0.1:8765\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from domino_data_capture.data_capture_client import DataCaptureClient\n",
    "from sklearn.metrics import accuracy_score\n",
    "import uuid\n",
    "import datetime\n",
    "import pickle\n",
    "import mlflow\n",
    "\n",
    "# Initiate MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Verify MLFLow URI\n",
    "print('MLFLOW_TRACKING_URI: ' + os.environ['MLFLOW_TRACKING_URI'])\n",
    "\n",
    "# Create an XGBoost model\n",
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=3,\n",
    "    learning_rate=1,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Optional, save the serialized model locally \n",
    "# file_name = \"models/xgb_iris.pkl\"\n",
    "# pickle.dump(xgb_classifier, open(file_name, \"wb\"))\n",
    "\n",
    "# Set up the DataCaptureClient. Pass feature names and the target column name.\n",
    "data_capture_client = DataCaptureClient(data.feature_names, [target_column_name])\n",
    "\n",
    "# Create a model Class to call that includes the DataCaptureClient.\n",
    "class IrisModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, context, model_input, params=None):\n",
    "        event_time = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "        prediction = self.model.predict(model_input)\n",
    "        \n",
    "        for i in range(len(prediction)):\n",
    "            # Record eventID and current time\n",
    "            event_id = uuid.uuid4()\n",
    "            # Convert np types to python builtin type to allow JSON serialization by prediction capture library\n",
    "            model_input_value = [float(x) for x in model_input[i]]\n",
    "            prediction_value = [data.target_names[prediction[i]]]\n",
    "            \n",
    "            # Capture this prediction event so Domino can keep track\n",
    "            data_capture_client.capturePrediction(model_input_value, prediction_value, event_id=event_id,\n",
    "                                timestamp=event_time)\n",
    "        return prediction\n",
    "\n",
    "model = IrisModel(xgb_classifier)\n",
    "\n",
    "model.model\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2909a-85cc-4c80-9db3-28a77867e22b",
   "metadata": {},
   "source": [
    "### Step 3: Register your Model in the Model Registry\n",
    "\n",
    "Before setting up the Model API, Domino recommends registering the new model in the Model Registry. The Model Registry tracks and manages all your machine learning models, providing documentation about how, when and where the model was created. In addition, the Model Registry allows collaborators to:\n",
    "\n",
    "- Discover models in project-scoped and deployment-scoped registries.\n",
    "\n",
    "- Record model metadata and lineage for auditability and reproducibility.\n",
    "\n",
    "- Create custom model cards to capture notes on fairness, bias, and other important information.\n",
    "\n",
    "- Manage model versions and deploy models to Domino-hosted or externally-hosted endpoints.\n",
    "\n",
    "This context will be useful once the model is being monitored, to help determine sources of drift or explain changes in accuracy detected by Domino Model Monitoring.\n",
    "\n",
    "See Model Registry documentation here:\n",
    "\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/3b6ae5/manage-models-with-model-registry/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "854c970b-34b5-4747-8d10-a982f80a0f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:17: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "Registered model 'DMM-Quickstart-Model-bryan_prosser-2024-09-19' already exists. Creating a new version of this model...\n",
      "2024/09/19 09:59:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: DMM-Quickstart-Model-bryan_prosser-2024-09-19, version 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.model.ModelInfo object at 0x7f055ec3f940>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'DMM-Quickstart-Model-bryan_prosser-2024-09-19'.\n"
     ]
    }
   ],
   "source": [
    "run_timestamp = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "mlflow.set_experiment(experiment_name=os.environ.get('DOMINO_PROJECT_NAME') + \" \" + os.environ.get('DOMINO_STARTING_USERNAME'))\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param('n_estimators', 10)\n",
    "    mlflow.log_param('max_depth', 3)\n",
    "    mlflow.log_param('learning_rate', 1)\n",
    "    mlflow.log_param('objective', \"binary:logistic\")\n",
    "    mlflow.log_param('random_state', 123)\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"DMM-Quickstart-Model-{}-{}\".format(user_name, run_timestamp),\n",
    "        python_model=model,\n",
    "        artifact_path=\"test-model\"\n",
    "    )\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d4cf1-a730-435f-a288-4de65f025997",
   "metadata": {},
   "source": [
    "### Step 4: Create Model API from the Model Card\n",
    "\n",
    "Once your model has been registered:\n",
    "\n",
    "1) Navigate to the model registry, open the Model Card for \"DMM-Quickstart-Model-DATE\" (or whatever you called your model)\n",
    "\n",
    "2) Create a new Model API with the name \"DMM-Quickstart-YOURNAME\" replacing your name as appropriate \n",
    "\n",
    "3) For Model API Source, select \"Choose Model From Model Registry\" and select \"DMM-Quickstart-Model\"\n",
    "\n",
    "4) Once the Model API is green and says \"Running\", navigate to the \"Configure Model Monitoring\" tab in the Model API. On the right, click \"Configure Monitoring\", and follow the instructions. Select your training set created above as the model baseline for drift, and set the model type to Classification.\n",
    "\n",
    "5) Score some data, using the sample Python code below. Be sure to update your URL and auth token to point to your Model API. A sample specific to your model is available in the Model API Overview tab. Domino Prediction Data Capture will capture these predictions in the back end.\n",
    "\n",
    "![alt text](readme_images/API_Request_Python.png)\n",
    "\n",
    "5) Wait for a bit. If you navigate to Domino Model Monitoring, the new model will appear. If you click into your new monitored model, under \"Overview\" in the \"Ingest History\" tab, the training data should be shown as ingested and \"Done\". However, under \"Data Drift\", your model will still say \"No Prediction Data Added\" for about an hour. The Model API Monitoring tab will say \"Waiting for Prediction Data.\" The prediction data from step 4 has been captured, but you have to wait for the first automated ingest for that drift data to appear in the Model Monitoring UI and to move to the next steps.\n",
    "\n",
    "6) Once data drift ingestion has happened, a new Domino Dataset called \"prediction_data\" will appear in your Project Domino Datasets list, and the Model Monitoring Data Drift section will populate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758ad02-a8e0-4069-9fae-fb755df457e4",
   "metadata": {},
   "source": [
    "### Save your model API URL, model API auth token, and DMM Model ID to the Project config file. \n",
    "\n",
    "To avoid saving the model API url & auth token in a git repo, we can save them to the config file directly in the Workbench.\n",
    "\n",
    "1) Navigate back to the Workbench, open the Artifacts section and open the 'DMM_config.yaml' file.\n",
    "2) Click \"Edit\", and copy and paste your new model url and auth token into the  \"integrated_model_url\" and \"integrated_model_auth\" fields.\n",
    "3) Navigate to Domino Model Monitoring. Click into your new model, copy the Model ID on the right, and save it to the 'integrated_model_id' field.\n",
    "4) Save the config file.\n",
    "5) Navigate back to your Workspace. In the File Changes menu on the left, pull all latest changes. Now the config file in this Workspace is in sync with the Project files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe56a962-7d9f-4a18-b8f6-f14b50417ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Date': 'Thu, 19 Sep 2024 11:08:38 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'X-Request-ID': '7EHOTK2VNAYZ1LPM', 'Domino-Server': 'nginx-ingress,model-api,', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'POST', 'Access-Control-Allow-Headers': 'authorization,content-type', 'Content-Security-Policy': \"frame-ancestors 'self' demo2.dominodatalab.com; \", 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'X-Frame-Options': 'SAMEORIGIN always', 'Content-Encoding': 'gzip'}\n",
      "{'model_time_in_ms': 8, 'release': {'harness_version': '0.1', 'registered_model_name': 'DMM-Quickstart-Model-bryan_prosser-2024-09-19', 'registered_model_version': '4'}, 'request_id': '7EHOTK2VNAYZ1LPM', 'result': [0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2], 'timing': 8.363962173461914}\n"
     ]
    }
   ],
   "source": [
    "# Test your new model API by sending some scoring data\n",
    "\n",
    "import yaml\n",
    "import requests\n",
    "\n",
    "# Load the config file\n",
    "with open(\"/mnt/artifacts/DMM_config.yaml\") as yamlfile:\n",
    "    config = yaml.safe_load(yamlfile)\n",
    "\n",
    " \n",
    "response = requests.post(config['integrated_model_url'], \n",
    "    auth=(\n",
    "            config['integrated_model_auth'],\n",
    "            config['integrated_model_auth'] \n",
    "    ),\n",
    "    json={\n",
    "       \"data\":  [  [4.3, 3. , 1.1, 0.1],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [6.7, 3. , 5.2, 2.3],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],\n",
    "        [5.8, 4. , 1.2, 0.2],\n",
    "        [5.7, 4.4, 1.5, 0.4],\n",
    "        [6.7, 3.3, 5.7, 2.5],]\n",
    "    }\n",
    ")\n",
    " \n",
    "print(response.status_code)\n",
    "print(response.headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a23c65-10c7-4217-80ab-1848f7a50b8a",
   "metadata": {},
   "source": [
    "### Step 5 (Optional): Register a Ground Truth Dataset\n",
    "\n",
    "Typically for this step you would fetch actual ground truth data (the actual outcomes from what your model predicted on), \n",
    "join the actual outcomes with your prediction data, and upload into a datasource attached to model monitoring for Model Quality \n",
    "analysis.\n",
    "\n",
    "However, for purposes of creating a quick demo, we'll make up some fake ground truth data using the model predictions captured with Domino's\n",
    "data capture client. These predictions are stored in an automatically-generated Domino Dataset called \"prediction_data\"\n",
    "\n",
    "Once Data has ingested (roughly one hour), a \"prediction_data\" Domino Dataset will be added to the Project.\n",
    "\n",
    "1) Navigate to the Domino Dataset Folder on the left (back from /mnt/ , then \"data/prediction_data/...\")\n",
    "Copy the path to read in your registered model predictions.\n",
    "\n",
    "2) Join the Predictions to make your ground truth dataset, shuffle some labels to simulate classification errors, and save the ground truth csv\n",
    "\n",
    "3) Upload the csv to the s3 bucket attached as a Domino Model Monitoring Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc08b19-6435-46e1-9dc0-59b6492f9c9b",
   "metadata": {},
   "source": [
    "#### Step 5.1 Connect an external data source to this Project and to Domino Model Monitoring\n",
    "\n",
    "Integrated models do not capture ground truth labels for you, since they are generally captured after the fact. Domino requires an external data source to ingest these ground truth labels.\n",
    "\n",
    "This example will use the same Monitoring Datasource set up in \"1_Initial_Setup.ipynb\", use the data source names saved in the config file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d5098-2b05-4d7b-bbac-bbb7c65ec740",
   "metadata": {},
   "source": [
    "#### Step 5.2 Create a \"dummy\" ground truth dataset and upload it to the external datasource\n",
    "\n",
    "Typically Ground Truth Data would be captured somewhere external to Domino, then uploaded to your Monitoring Datasource. A call to the DMM API can alert DMM that new ground truth data is available for ingestion.\n",
    "\n",
    "However, in this example, we will have to create our own \"dummy\" ground truth data, using the scoring and prediction data captured but the DataCaptureClient set up in Step 2. \n",
    "\n",
    "The DataCaptureClient automatically saves scoring and prediction data in a parquet file in a new Domino Dataset in this Project called \"prediction_data\". \n",
    "\n",
    "1) Ensure the first batch of predictions have been ingested into your new model. A new Domino Dataset called \"prediction_data\" should be created and populated with a folder containing the initial prediction data captured.\n",
    "3) In this Workspace, navigate to the \"prediction_data\" Domino dataset (under \"/mnt/data/prediction_data\"), copy the file path to one of the parquet files in there.\n",
    "\n",
    "The path should be formatted like this:\n",
    "\n",
    "\"/mnt/data/prediction_data/{PREDICTION_DATA_ID}/{DATE}/{TIME}/predictions_{ID}.parquet\"\n",
    "\n",
    "Paste in the cell below, and take a look at the captured prediction data and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26602162-e1c8-4563-9632-90d291020079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>__domino_timestamp</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-09-19 10:41:29.011733+00:00</td>\n",
       "      <td>2024-09-19T10:41:29.017039+00:00</td>\n",
       "      <td>53094281-60e9-48eb-8922-a2afd00a1ed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-09-19 10:41:29.011733+00:00</td>\n",
       "      <td>2024-09-19T10:41:29.017500+00:00</td>\n",
       "      <td>85cbdeee-ade8-4f3d-9f6b-8d012d373bb8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-09-19 10:41:29.011733+00:00</td>\n",
       "      <td>2024-09-19T10:41:29.017814+00:00</td>\n",
       "      <td>e81b0176-f613-4222-8a31-09d20657eb1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2024-09-19 10:41:29.011733+00:00</td>\n",
       "      <td>2024-09-19T10:41:29.018039+00:00</td>\n",
       "      <td>6cbb14ab-9226-4111-aa7f-8521ea2ba13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-09-19 10:41:29.011733+00:00</td>\n",
       "      <td>2024-09-19T10:41:29.018257+00:00</td>\n",
       "      <td>d5d3f840-7003-457a-ab5d-36cfef7c3e5d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal length (cm)  petal width (cm)  sepal length (cm)  sepal width (cm)  \\\n",
       "0                1.1               0.1                4.3               3.0   \n",
       "1                1.2               0.2                5.8               4.0   \n",
       "2                1.5               0.4                5.7               4.4   \n",
       "3                5.7               2.5                6.7               3.3   \n",
       "4                1.2               0.2                5.8               4.0   \n",
       "\n",
       "     variety                        timestamp  \\\n",
       "0     setosa 2024-09-19 10:41:29.011733+00:00   \n",
       "1     setosa 2024-09-19 10:41:29.011733+00:00   \n",
       "2     setosa 2024-09-19 10:41:29.011733+00:00   \n",
       "3  virginica 2024-09-19 10:41:29.011733+00:00   \n",
       "4     setosa 2024-09-19 10:41:29.011733+00:00   \n",
       "\n",
       "                 __domino_timestamp                              event_id  \n",
       "0  2024-09-19T10:41:29.017039+00:00  53094281-60e9-48eb-8922-a2afd00a1ed3  \n",
       "1  2024-09-19T10:41:29.017500+00:00  85cbdeee-ade8-4f3d-9f6b-8d012d373bb8  \n",
       "2  2024-09-19T10:41:29.017814+00:00  e81b0176-f613-4222-8a31-09d20657eb1c  \n",
       "3  2024-09-19T10:41:29.018039+00:00  6cbb14ab-9226-4111-aa7f-8521ea2ba13b  \n",
       "4  2024-09-19T10:41:29.018257+00:00  d5d3f840-7003-457a-ab5d-36cfef7c3e5d  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# UPDATE this PATH\n",
    "path = '/mnt/data/prediction_data/66ebfdc26a949b24c2955885/$$date$$=2024-09-19Z/$$hour$$=10Z/predictions_69a9ffe8-d4ec-458c-ae06-07e30db35dd5.parquet'\n",
    "\n",
    "predictions = pd.read_parquet(path)\n",
    "\n",
    "# Save the prediction_data_dir ID to the config file\n",
    "with open(\"/mnt/artifacts/DMM_config.yaml\") as yamlfile:\n",
    "    config = yaml.safe_load(yamlfile)\n",
    "\n",
    "config['prediction_data_dir'] = path.split('/')[4]\n",
    "\n",
    "with open(\"/mnt/artifacts/DMM_config.yaml\", \"w\") as yamlfile:\n",
    "    config = yaml.dump(\n",
    "        config, stream=yamlfile, default_flow_style=False, sort_keys=False\n",
    "    )\n",
    "    \n",
    "print(predictions.shape)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36478b4f-53de-4a11-879e-b7a82875a892",
   "metadata": {},
   "source": [
    "The Ground Truth dataset needs 2 columns: \n",
    "\n",
    "1) The existing event ID column from the model predictions.\n",
    "   \n",
    "    This column has the join keys for joining ground truth labels to your model's predictions\n",
    "\n",
    "3) Your new column containing ground truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0abbad2-3785-4cc8-b10c-608bc82ecfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "event_id = predictions['event_id']\n",
    "iris_ground_truth = predictions['variety']\n",
    "\n",
    "# Create a new dataframe\n",
    "ground_truth = pd.DataFrame(columns=['event_id', 'iris_ground_truth'])\n",
    "ground_truth['event_id'] = event_id\n",
    "ground_truth['iris_ground_truth'] = iris_ground_truth\n",
    "\n",
    "# These row labels help find some diferent iris types in our initial scoring data\n",
    "end_index = predictions.shape[0]\n",
    "mid_index = int(round(predictions.shape[0] / 2, 0))\n",
    "\n",
    "# Simulate some classifcation errors. This makes our confusion matrix interesting.\n",
    "ground_truth.iloc[0, 1] = 'virginica'\n",
    "ground_truth.iloc[1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index-1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index, 1] = 'virginica'\n",
    "ground_truth.iloc[end_index-2, 1] = 'setosa'\n",
    "ground_truth.iloc[end_index-1, 1] = 'setosa'\n",
    "\n",
    "# Save this example ground truth csv to your file to your Project files for reference.\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day\n",
    "year = date.year\n",
    "\n",
    "date = str(datetime.datetime.today()).split()[0]\n",
    "\n",
    "ground_truth.to_csv('data/{}_iris_ground_truth_{}_{}_{}.csv'.format(user_name, month, day, year), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f80dd9-4bc3-45a5-a39e-58363fa45adc",
   "metadata": {},
   "source": [
    "#### Step 5.3 Upload the ground truth file to a Domino Model Monitoring data source.\n",
    "\n",
    "Ground truth labels must come from an external data source attached to Domino Model Monitoring. The Model API does not capture ground truth labels, since they typically become available after the prediction.\n",
    "\n",
    "The AWS example uses a Domino Data Source, you could also use boto3 or other methods to upload data to s3.\n",
    "\n",
    "The Azure example uses a Domino Data Source with ADLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d7d91-b77a-4c67-94c4-cda5e12e9680",
   "metadata": {},
   "source": [
    "#### AWS: s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e3e5cb-18de-41ab-a5a4-acdb85b49d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For this approach, add an s3 Domino Data Source bucket to your Project. Then, copy the first fe linwes of the automatically generated Python code.\n",
    "from domino.data_sources import DataSourceClient\n",
    "import yaml\n",
    "\n",
    "# Load the config file\n",
    "with open(\"/mnt/artifacts/DMM_config.yaml\") as yamlfile:\n",
    "    config = yaml.safe_load(yamlfile)\n",
    "\n",
    "# instantiate a client and fetch the datasource instance\n",
    "object_store = DataSourceClient().get_datasource(config['workbench_datasource_name']) \n",
    "\n",
    "# list objects available in the datasource\n",
    "objects = object_store.list_objects()\n",
    "\n",
    "object_store.upload_file(\"{}_iris_ground_truth_{}_{}_{}.csv\".format(user_name, month, day, year), \"data/{}_iris_ground_truth_{}_{}_{}.csv\".format(user_name, month, day, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd0908-c896-4f36-8a95-6ba34abac514",
   "metadata": {},
   "source": [
    "#### Azure: ADLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32068724-fb79-4ce3-a4e1-58fdff902bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from domino.data_sources import DataSourceClient\n",
    "\n",
    "# # instantiate a client and fetch the datasource instance\n",
    "# object_store = DataSourceClient().get_datasource(\"adlsdatasource\")\n",
    "\n",
    "# # list objects available in the datasource\n",
    "# objects = object_store.list_objects()\n",
    "\n",
    "# object_store.upload_file(\"iris_ground_truth_{}_{}_{}.csv\".format(month, day, year), \"data/iris_ground_truth_{}_{}_{}.csv\".format(month, day, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6b059-5c41-43dc-9526-ae6ece5f4787",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 5.4 First Time Registration of Ground Truth Labels via the API\n",
    "\n",
    "The final step is to register Ground Truth Labels with Domino Model Monitoring.\n",
    "\n",
    "This can be done in the Model Monitoring UI using the Ground Truth Config file, or using the Domino Model Monitoring API.\n",
    "\n",
    "Documentation here: https://docs.dominodatalab.com/en/latest/api_guide/f31cde/model-monitoring-api-reference/#_registerDatasetConfig\n",
    "\n",
    "You’ll need the following:\n",
    "\n",
    "1) The Monitoring Dataset & config file set up in \"1_Initial_Setup.ipynb\". Make sure you have synced the workspace since Step 4 to add your DMM model ID to the config file.\n",
    "    \n",
    "2) The column name of your new, ground truth labels \n",
    "\n",
    "3) Your original target (or prediction) column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e75973-c2f9-429e-aa4e-b8b1c029aaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering bryan_prosser_iris_ground_truth_9_19_2024.csv From S3 Bucket in DMM\n",
      "b'[\"Dataset already registered with the model.\"]'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "# The name of the file uploaded to s3 above\n",
    "gt_file_name = \"{}_iris_ground_truth_{}_{}_{}.csv\".format(user_name, month, day, year)\n",
    "\n",
    "# The name of the column containing ground truth labels\n",
    "GT_column_name = 'iris_ground_truth'\n",
    "\n",
    "# Your original target column name\n",
    "target_column_name = 'variety'\n",
    "\n",
    "# Load the config file\n",
    "with open(\"/mnt/artifacts/DMM_config.yaml\") as yamlfile:\n",
    "    config = yaml.safe_load(yamlfile)\n",
    "\n",
    "\n",
    "ground_truth_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/ground_truth\".format(config['url'], config['integrated_model_id'])\n",
    "\n",
    "print('Registering {} From S3 Bucket in DMM'.format(gt_file_name))\n",
    " \n",
    "# create GT payload    \n",
    " \n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': os.environ['DOMINO_USER_API_KEY'],\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    " \n",
    "ground_truth_payload = \"\"\"\n",
    "{{\n",
    "    \"variables\": [{{\n",
    "    \n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"ground_truth\",\n",
    "            \"name\": \"{2}\", \n",
    "            \"forPredictionOutput\": \"{3}\"\n",
    "        \n",
    "    }}],\n",
    "    \"datasetDetails\": {{\n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"{4}\"\n",
    "        }}\n",
    "}}\n",
    "\"\"\".format(gt_file_name, config['DMM_datasource_name'], GT_column_name, target_column_name, config['datasource']['type'])\n",
    " \n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", ground_truth_url, headers=headers, data = ground_truth_payload)\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc660f-f094-4b83-bc2a-935b835e9c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next Steps\n",
    "\n",
    "Going forward, Domino will automatically capture all prediction data going across your Model API. It will ingest these predictions for Drift detection once per day. You can set a schedule to determine when this ingest happens.\n",
    "\n",
    "To periodically upload ground truth labels, repeat the previous step, but without the “variables” in the ground truth payload (this only needs to be done once). As new ground truth labels are added, point Domino to the path to the new labels in the monitoring data source by pinging the same Model Monitoring API:\n",
    "\n",
    "ground_truth_payload = \"\"\"\n",
    "\n",
    "{{\n",
    "\n",
    "       \"datasetDetails\": {{\n",
    "        \n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"s3\"\n",
    "        }}\n",
    "}}\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd486-42bb-48e7-85e5-2d4ed3056f18",
   "metadata": {},
   "source": [
    "### Automation with Domino Jobs\n",
    "To simulate Domino Model Monitoring over time, you can try out running the following two scripts as scheduled Domino Jobs:\n",
    "\n",
    "Scripts are in the \"integrated_model_scripts\" directory.\n",
    "\n",
    "**(1) daily_scoring.py**\n",
    "\n",
    "Daily scoring simulates sending data to the model API for scoring. Data is read in, sent to the Domino Model API, and predictions are returned. Domino's Prediction Capture Client captures the scoring data and model predictions. Every 24 hours, the captured data is ingested into the Drift Monitoring dashboard. Note that while this example uses a batch job, integrated model APIs capture both batch and real time data sent to the API.\n",
    "\n",
    "**(2) daily_ground_truth.py**\n",
    "\n",
    "Daily ground truth simulates uploading actual outcomes after the predictions have been made. A scheduled Domino Job writes the latest ground truth labels to an s3 bucket, then calls the Domino Model Monitoring API with the path to the file with the latest ground truth labels.\n",
    "\n",
    "**Important**\n",
    "If you schedule these two jobs, be sure that daily_ground_truth.py runs after both daily_scoring.py and the scheduled drift check in DMM.\n",
    "\n",
    "Suggested schedule:\n",
    "\n",
    "daily_scoring.py - scheduled Domino Job at 1am\n",
    "\n",
    "Data Drift check in DMM - scheduled for 2am\n",
    "\n",
    "daily_ground_truth.py - scheduled Domino Job at 3am"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
