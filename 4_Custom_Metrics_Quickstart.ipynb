{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d368f0-adf0-4fa1-89a4-fe3e2528ca93",
   "metadata": {},
   "source": [
    "### Custom Metrics SDK\n",
    "\n",
    "Use Dominoâ€™s Custom Model Monitoring Metrics SDK to define custom metrics and use them alongside out-of-the-box drift and model quality metrics that are monitored in Domino Model Monitor. With this SDK, you can register new metrics and define the logic to compute them. You can author this logic and evaluate it from within a Domino project.\n",
    "\n",
    "For every model that you register for monitoring, you can select a registered metric, associate the data sources from which the metric is computed, and set up the execution environment to compute this metric on a periodic basis. You are notified by email when a metric behaves abnormally based on threshold definitions.\n",
    "\n",
    "For end-to-end working code with a description of the workflow, see the custom metrics example folder in the quick-start project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46987f7-f637-4875-a885-10ca49ac6ada",
   "metadata": {},
   "source": [
    "### Step 1: Instantiate the client\n",
    "\n",
    "First, start the custom_metrics_client, and assign the custom metric to an exisitng model in Domino Model Monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de161c8-b211-4bd4-af44-cbb77057c5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<domino._custom_metrics._CustomMetricsClientGen at 0x7fd5c7183a60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import domino\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "d = domino.Domino(\n",
    "    \"{}/{}\".format(os.environ['DOMINO_USER_NAME'], os.environ['DOMINO_PROJECT_NAME']),\n",
    "    api_key=os.environ[\"DOMINO_USER_API_KEY\"],\n",
    "    host=os.environ[\"DOMINO_API_HOST\"],\n",
    ")\n",
    "\n",
    "# Load the config file\n",
    "with open(\"/mnt/artifacts/DMM_config.yaml\") as yamlfile:\n",
    "    config = yaml.safe_load(yamlfile)\n",
    "\n",
    "# Attach alerts to the external model built in \"2_External_DMM_Quickstart.ipynb\" \n",
    "dmm_model_id = config['external_model_id']\n",
    "\n",
    "# Initiate the Project\n",
    "# d = domino.Domino(\"{}/{}\".format(os.environ['DOMINO_USER_NAME'], os.environ['DOMINO_PROJECT_NAME']))\n",
    "metrics_client = d.custom_metrics_client()\n",
    "\n",
    "metrics_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8a258-d114-4acd-9a72-af2c9a7261c3",
   "metadata": {},
   "source": [
    "### Log the custom metrics:\n",
    "\n",
    "**modelMonitoringId:** ID of the monitored model to send metric alerts for\n",
    "\n",
    "**metric**: Name of the metric to send alert for\n",
    "\n",
    "**value:** Value of the metric\n",
    "\n",
    "**timestamp:** Timezone is in UTC in ISO 8601 format.\n",
    "\n",
    "**tags:** Custom metadata for metric represented as key-value string pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f15dbb-6b20-4a7a-becc-24867a407d45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define your custom metric\n",
    "\n",
    "Custom Metric for Iris Use Case: Hellinger Diatance\n",
    "\n",
    "https://en.wikipedia.org/wiki/Hellinger_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725a584d-df90-439b-be3a-633b776455ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hellinger_distance(train, inference):\n",
    "    \n",
    "    # distance between training data and inference data\n",
    "    # train is the ditribution of an input feature in the training data\n",
    "    # inference is the dsitribution of a feature being sent to the model API\n",
    "    \n",
    "    n = min(len(train), len(inference))\n",
    "    sum = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        sum += (np.sqrt(train[i]) - np.sqrt(inference[i]))**2\n",
    "        \n",
    "    result = (1.0 / np.sqrt(2.0)) * np.sqrt(sum)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785a782-6eb5-4c7d-9412-9d99bac120e6",
   "metadata": {},
   "source": [
    "#### Fetch Training set distribution for selected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c0e109-03d2-4436-b1ac-417d8aa4e7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8899/access-token \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://nucleus-frontend.domino-platform/trainingset/find?offset=0&limit=10000&asc=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8899/access-token \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://nucleus-frontend.domino-platform/trainingset/iris_python_multi_classification_monitor_workshop/1 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrainingSet(name='iris_python_multi_classification_monitor_workshop', project_id='66ebdecd276d7e51a2b1477d', description=<training_set_api_client.types.Unset object at 0x7fd5c6b01150>, meta={})]\n",
      "0    1.6\n",
      "1    1.5\n",
      "2    4.4\n",
      "3    1.6\n",
      "4    4.2\n",
      "Name: petal length (cm), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Metric\n",
    "from domino.training_sets import TrainingSetClient, model\n",
    "\n",
    "# Column we want to calculate metric for\n",
    "drift_column_name = 'petal length (cm)'\n",
    "\n",
    "# Print existing Training Sets in this Project\n",
    "\n",
    "ts = TrainingSetClient.list_training_sets()\n",
    "print(ts)\n",
    "\n",
    "training_set = TrainingSetClient.get_training_set_version(\n",
    "    training_set_name = \"iris_python_multi_classification_{}\".format(os.environ.get('DOMINO_PROJECT_NAME')),\n",
    "    number=1\n",
    "    )\n",
    "\n",
    "training_df = training_set.load_training_pandas()\n",
    "train = training_df[drift_column_name]\n",
    "\n",
    "print(train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc071a0d-3baa-4d5b-939f-c1f234e3b468",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fetch Inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e302e39-725a-40a9-964f-e14b5c952e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scoring_data = pd.read_csv('/mnt/code/data/external_model_scoring_data.csv')\n",
    "\n",
    "inference = scoring_data[drift_column_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3a898-8060-4aa6-a39f-eb0e8c997bb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate your metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08d1b2e-1813-4e12-93bb-4f15935fa594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellinger distance between scoring and traiing data is: 5.104\n"
     ]
    }
   ],
   "source": [
    "hellinger_distance = hellinger_distance(train, inference)\n",
    "print('Hellinger distance between scoring and traiing data is: {}'.format(str(round(hellinger_distance, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539abd8-5202-458c-8967-64c71e8e724a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Log your metric with Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064ee4dd-c4b4-4a96-b7d5-53631d7c8158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Unable to fetch metrics\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "DynamicSchema({'metricValues': (), 'metadata': DynamicSchema({'requestId': '768835ce-f0f3-4932-aee2-200af6115507', 'notices': ()})}) has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     17\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to fetch metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Retrieve the metrics over the last year\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmm_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhellinger_distance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartDate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendDate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     17\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to fetch metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/domino/_custom_metrics.py:187\u001b[0m, in \u001b[0;36m_CustomMetricsClientGen.read_metrics\u001b[0;34m(self, model_monitoring_id, metric, start_timestamp, end_timestamp)\u001b[0m\n\u001b[1;32m    184\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mrequest_manager\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    185\u001b[0m mvs: MetricValuesEnvelopeV1 \u001b[38;5;241m=\u001b[39m MetricValuesEnvelopeV1\u001b[38;5;241m.\u001b[39mfrom_openapi_data_oapg(res)\n\u001b[1;32m    186\u001b[0m ret \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(\u001b[43mmvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m),\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetricValues\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_metric_value(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mvs\u001b[38;5;241m.\u001b[39mmetricValues],\n\u001b[1;32m    189\u001b[0m }\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/domino/_impl/custommetrics/schemas.py:1729\u001b[0m, in \u001b[0;36mDictBase.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name)\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m:\n\u001b[0;32m-> 1729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[name]\n",
      "\u001b[0;31mAttributeError\u001b[0m: DynamicSchema({'metricValues': (), 'metadata': DynamicSchema({'requestId': '768835ce-f0f3-4932-aee2-200af6115507', 'notices': ()})}) has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "# Retrieve the stored metrics for the last 3 years \n",
    "import datetime\n",
    "from datetime import timezone\n",
    "import logging\n",
    "import rfc3339\n",
    "\n",
    "# Get time stamps for now and 1 year ago\n",
    "startDate = datetime.datetime.today() - datetime.timedelta(days=365*3)\n",
    "startDate = rfc3339.rfc3339(startDate)\n",
    "endDate = rfc3339.rfc3339(datetime.datetime.today())\n",
    "\n",
    "# Retrieve the metrics over the last year\n",
    "try:\n",
    "    res = metrics_client.read_metrics(dmm_model_id, \"hellinger_distance\", startDate, endDate)\n",
    "    \n",
    "except Exception as err:\n",
    "    logging.error(\"Unable to fetch metrics\")\n",
    "    raise err\n",
    "    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f8491f-2ae1-41c8-afdd-4df9fbb856a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66342446965e21e5b0d56d43\n",
      "9\n",
      "2024-05-08T21:43:20+00:00\n",
      "petal length (cm)\n"
     ]
    }
   ],
   "source": [
    "# timestamp = \"2023-12-17T00:00:00Z\"\n",
    "timestamp = rfc3339.rfc3339(datetime.datetime.now()) # datetime.datetime.now().isoformat()\n",
    "\n",
    "print(dmm_model_id)\n",
    "print(hellinger_distance)\n",
    "print(timestamp)\n",
    "print(drift_column_name)\n",
    "\n",
    "metrics_client.log_metric(dmm_model_id, \"hellinger_distance\", hellinger_distance, timestamp, { \"Column\" : drift_column_name})\n",
    "\n",
    "# Sample code for logging multiple metrics\n",
    "# metrics_client.log_metrics([\n",
    "# { \"modelMonitoringId\" : dmm_model_id, \"metric\" : \"accuracy\", \"value\" : 7.1234,\n",
    "# \"timestamp\" : \"2022-10-08T00:00:00Z\",\n",
    "# \"tags\" : { \"example_tag1\" : \"value1\", \"example_tag2\" : \"value2\" }\n",
    "# ]\n",
    "# },\n",
    "# { \"modelMonitoringId\" : dmm_model_id, \"metric\" : \"other_metric\", \"value\" : 8.4567,\n",
    "# \"timestamp\" : \"2022-10-09T00:00:00Z\" }\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39782a8e-19b1-4dd2-89bb-34a14d00c1c7",
   "metadata": {},
   "source": [
    "#### Send a custom metrics alert:\n",
    "\n",
    "**modelMonitoringId:** ID of the monitored model for which to send metric alerts.\n",
    "\n",
    "**metric:** Name of the metric for which to send the alert.\n",
    "\n",
    "**value:** Value of the metric.\n",
    "\n",
    "**condition:** Target range for the metric defined by lower and upper limit bounds.\n",
    "The following are potential values for the condition argument:\n",
    "\n",
    "    metrics_client.LESS_THAN = \"lessThan\"\n",
    "\n",
    "    metrics_client.LESS_THAN_EQUAL = \"lessThanEqual\"\n",
    "\n",
    "    metrics_client.GREATER_THAN = \"greaterThan\"\n",
    "\n",
    "    metrics_client.GREATER_THAN_EQUAL = \"greaterThanEqual\"\n",
    "\n",
    "    metrics_client.BETWEEN = \"between\"\n",
    "\n",
    "**lower_limit:** The lower limit for the condition.\n",
    "\n",
    "**upper_limit:** The upper limit for the condition.\n",
    "\n",
    "**description:** Optional message included in the alert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add167f6-aa91-42c4-aad9-6d989ebd064f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set alert above threshold\n",
    "dmm_model_id = config['external_model_id']\n",
    "drift_column_name = 'petal length (cm)'\n",
    "timestamp = rfc3339.rfc3339(datetime.datetime.now())\n",
    "\n",
    "hellinger_distance = 9\n",
    "\n",
    "metrics_client.log_metric(dmm_model_id, \"hellinger_distance\", hellinger_distance, timestamp, { \"Column\" : drift_column_name})\n",
    "\n",
    "\n",
    "metrics_client.trigger_alert(dmm_model_id, \n",
    "                             \"hellinger_distance\", \n",
    "                             hellinger_distance, \n",
    "                             condition = metrics_client.BETWEEN, \n",
    "                             lower_limit=6,\n",
    "                             upper_limit=8,\n",
    "                             description = \"Hellinger distance breached 6.0-8.0 range.\" \n",
    "                            )"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
